{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad291cec-aa7b-444a-9866-73d29a206613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d4ed40-1f63-4fea-afef-9f2c73e6dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_link = 'https://comicbookrealm.com/series/5871/0/image-comics-the-walking-dead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dd18c7c-590e-4c88-ac46-92cd7a3cdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_chrome(headless=True, driver_path='./'):\n",
    "    # use selenium webdriver so we can scrape the javascript elements\n",
    "    # chromedriver should be in the path or it should be provided. version should correspond to the chrome version installed\n",
    "    # Link for versions: https://chromedriver.chromium.org/downloads\n",
    "    if headless:\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        opts = Options()\n",
    "        opts.add_argument('--blink-settings=imagesEnabled=false')\n",
    "        opts.add_argument(\" --headless\")\n",
    "        chrome_driver = \"chromedriver\"# Instantiate a webdriver\n",
    "        browser = webdriver.Chrome(options=opts, executable_path=driver_path+chrome_driver)# Load the HTML page\n",
    "    else:\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        opts = Options()\n",
    "        opts.add_argument('--blink-settings=imagesEnabled=false')\n",
    "        chrome_driver = \"chromedriver\"\n",
    "        browser = webdriver.Chrome(options=opts, executable_path=driver_path+chrome_driver)\n",
    "\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def issue_scraper(browser, issue_link, issue_nr, cover_link, title, title_link, sleep_time=0.8):\n",
    "    \n",
    "    data_dict = {'title': title, \n",
    "                 'title_link': title_link, \n",
    "                 'issue_link': issue_link,\n",
    "                 'cover_link': cover_link}\n",
    "    \n",
    "    browser.get(issue_link)\n",
    "    # WebDriverWait(browser, wait_time).until(EC.visibility_of_any_elements_located((By.CLASS_NAME, 'page_1')))\n",
    "    time.sleep(sleep_time + random.random())\n",
    "    try:\n",
    "        # click on accept cookies and privacy aggreements\n",
    "        browser.find_elements_by_xpath(\"//button[@class=' css-47sehv']\")[0].click()\n",
    "        time.sleep(1) # wait a bit for the page to load\n",
    "        browser.find_elements_by_xpath(\"//a[@class='cc_btn cc_btn_accept_all']\")[0].click()\n",
    "        time.sleep(1) # wait a bit for the page to load\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    soup_file = browser.page_source\n",
    "    soup = BeautifulSoup(soup_file, 'html.parser')\n",
    "    issue_data = (soup.find('div', id='comic-details-content')\n",
    "                     .find('table', class_='auto-table')\n",
    "                     .find_all('td', class_='data')\n",
    "                 )\n",
    "    issue_labels = (soup.find('div', id='comic-details-content')\n",
    "                        .find('table', class_='auto-table')\n",
    "                        .find_all('td', class_='label')\n",
    "                   )\n",
    "    labels = ['issue', 'cover_date', 'cover_price', 'current_value',\n",
    "        'searched', 'owned', 'pages', 'rating', 'ISBN-UPC', \n",
    "       'est_print_run', 'variant_of', 'preview']\n",
    "\n",
    "    for dat, label, lab in zip(issue_data, issue_labels, labels):\n",
    "        data_dict[lab] = dat.text.strip()\n",
    "        if label.text == 'Current Value:':\n",
    "            data_dict['hist_prices_link'] = dat.find('a').get('href')\n",
    "        if dat.find('img') is not None and label.text == 'Rating:':\n",
    "            rating = dat.find('img').get('title')\n",
    "            rating = re.findall(\"\\d+\\.\\d+|\\d+\", rating)\n",
    "            data_dict['rating'] = float(rating[0])\n",
    "            data_dict['rating_count'] = int(rating[1])\n",
    "            \n",
    "    data_dict['synopsis'] = soup.find('div', id='synopsis').text.strip()\n",
    "    # get info from contributors tab\n",
    "    browser.find_elements_by_xpath(\"//li[@ref='contributors']\")[0].click()\n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "    soup_file = browser.page_source\n",
    "    soup = BeautifulSoup(soup_file, 'html.parser')\n",
    "    creators = soup.find('div', id='contributors').find_all('li')\n",
    "    \n",
    "    if len(creators) == 1 and creators[0].text == 'There have been no contributors assigned to this issue':\n",
    "        names = 'no contributors assigned'\n",
    "        jobs = 'no contributors assigned'\n",
    "    else:\n",
    "        names = []\n",
    "        jobs = []\n",
    "        for li in creators:\n",
    "            contrib = li.text.strip()\n",
    "            names.append(contrib.split('\\n', 1)[0])\n",
    "            j = contrib.split('\\n', 1)[1]\n",
    "            jobs.append(re.sub('\\s*', '', j))\n",
    "\n",
    "    \n",
    "    data_dict['contributors_names'] = str(names)\n",
    "    data_dict['contributors_roles'] = str(jobs)\n",
    "    \n",
    "    # get info from characters tab\n",
    "    browser.find_elements_by_xpath(\"//li[@ref='characters']\")[0].click()\n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "    soup_file = browser.page_source\n",
    "    soup = BeautifulSoup(soup_file, 'html.parser')\n",
    "    \n",
    "    characters = soup.find('div', id='characters').find_all('li')\n",
    "    \n",
    "    if len(characters) == 1 and characters[0].text == 'There have been no characters assigned to this issue':\n",
    "        character_data = 'no characters assigned'\n",
    "    \n",
    "    else:\n",
    "        character_data = []\n",
    "        for li in characters:\n",
    "            name = li.find('a').text.strip()\n",
    "            photo_link = li.find('img').get('src')\n",
    "            extra_info = li.find('span').text.strip()\n",
    "            if '(' not in extra_info:\n",
    "                extra_info = ''\n",
    "\n",
    "            event = li.find('span', class_='d').text.strip()\n",
    "            character_data.append([name, photo_link, extra_info, event])\n",
    "    \n",
    "    data_dict['characters'] = str(character_data)\n",
    "    \n",
    "    return pd.DataFrame(data_dict, index=[0])\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d943a0eb-0463-4c5f-b00f-958d442bc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('all_issues_list_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdb4eb61-1ce3-447c-8606-578b19a337e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser = start_chrome(headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed8d9085-ea31-47ec-8afe-29ae0e1ba9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the scraper function\n",
    "# index = 10000\n",
    "# issue_link = df.issue_link[index]\n",
    "# issue_nr = df.issue_nr[index]\n",
    "# cover_link = df.cover_link[index]\n",
    "# title = df.title[index]\n",
    "# title_link = df.title_link[index]\n",
    "# sleep_time=1\n",
    "\n",
    "# site_link = 'https://comicbookrealm.com'\n",
    "\n",
    "# data = issue_scraper(browser, site_link+issue_link, issue_nr, cover_link, title, title_link, sleep_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e30ab-1491-4195-9e77-0c30bde9ef79",
   "metadata": {},
   "source": [
    "### Make the scraper loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceaae757-265c-466c-9798-98fa537f1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_issues_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79946864-2bb5-4e2a-8b87-f57fb90bbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = start_chrome(headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "510849b6-b994-46e1-a5b8-66bd08ae8dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23126ebd934045d7b1d12fe36d39bee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This comic was rated 0.00 stars by 0 members ['0.00', '0']\n"
     ]
    }
   ],
   "source": [
    "site_link = 'https://comicbookrealm.com'\n",
    "sleep_time = 1\n",
    "df1 = df.iloc[31:32]\n",
    "\n",
    "iterates = tqdm(zip(range(df1.shape[0]), \n",
    "                    df1.issue_link, \n",
    "                    df1.issue_nr, \n",
    "                    df1.cover_link, \n",
    "                    df1.title,\n",
    "                    df1.title_link,\n",
    "                   )\n",
    "               )\n",
    "\n",
    "frames_list = []\n",
    "\n",
    "for i, issue_link, issue_nr, cover_link, title, title_link in iterates:\n",
    "    \n",
    "    iterates.set_description(f\"Processing: {title}: {issue_nr} - {i + 1} / {df1.shape[0]}\")\n",
    "    \n",
    "    try:\n",
    "        frame = issue_scraper(browser, site_link+issue_link, issue_nr, cover_link, title, title_link, sleep_time)\n",
    "    \n",
    "    except AttributeError:\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            frame = issue_scraper(browser, site_link+issue_link, issue_nr, cover_link, title, title_link, sleep_time)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "        \n",
    "    \n",
    "    frames_list.append(frame)\n",
    "    \n",
    "    if i%10000 == 0 and i > 0:\n",
    "        temp = pd.concat(frames_list, axis=0)\n",
    "        temp.to_csv(f'issues_data_{i}.csv')\n",
    "\n",
    "browser.quit()\n",
    "dff = pd.concat(frames_list, axis=0).reset_index(drop=True)   \n",
    "dff.to_csv('single_issue_data_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a33a829-dd12-4bd6-8325-08b993ad81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00', '0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\d+\\.\\d+|\\d+\", 'This comic was rated 0.00 stars by 0 members')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcd7125a-7fd9-4536-adb0-8396ac3e5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat(frames_list, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed074985-70a2-4acd-bd3b-12ecd5421f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/series/43774/379663/dc-comics-52-tpb-tpb-1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b83ccd7-403c-43ac-ae99-0b3d0b1a5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60b2fe9a-eed5-44e2-88cc-351e3386c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('single_issue_data_part1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e245e0-655e-4350-a8fe-cee3ca895f76",
   "metadata": {},
   "source": [
    "## Minimal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe47ee18-a5c8-4df5-b5eb-d92bc1ba48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = start_chrome(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad615934-5c68-444e-a737-d2ba0e6de7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(main_link)\n",
    "# WebDriverWait(browser, wait_time).until(EC.visibility_of_any_elements_located((By.CLASS_NAME, 'page_1')))\n",
    "time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eeba050b-7e4e-4e11-9cf1-8ac0476640e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_file = browser.page_source\n",
    "soup = BeautifulSoup(soup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c918474c-24c2-49f1-8227-d3430b9bcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_data = soup.find('div', id='comic-details-content').find('table', class_='auto-table').find_all('td', class_='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c0ab5f0-c08b-48fd-8493-1ec916d038c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_labels = soup.find('div', id='comic-details-content').find('table', class_='auto-table').find_all('td', class_='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55ee8505-be26-40f1-8838-3bfb92e0b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n"
     ]
    }
   ],
   "source": [
    "labels = ['issue', 'cover_date', 'cover_price', 'current_value',\n",
    "        'searched', 'owned', 'pages', 'rating', 'ISBN-UPC', \n",
    "       'est_print_run', 'variant_of', 'preview']\n",
    "\n",
    "data_dict = {}\n",
    "for dat, label, lab in zip(issue_data, issue_labels, labels):\n",
    "    data_dict[lab] = dat.text.strip()\n",
    "    if label.text == 'Current Value:':\n",
    "        data_dict['hist_prices_link'] = dat.find('a').get('href')\n",
    "    if dat.find('img') is not None and label.text != 'Current Value:':\n",
    "        print(lab)\n",
    "        rating = dat.find('img').get('title')\n",
    "        rating = re.findall(\"\\d+\\.\\d+|\\d+\", rating)\n",
    "        data_dict['rating'] = float(rating[0])\n",
    "        data_dict['rating_count'] = int(rating[1])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c9544a5e-118f-4371-8d49-0917613df809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['synopsis'] = soup.find('div', id='synopsis').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a373af1-b4da-427a-b3a5-65a42c3ef50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_elements_by_xpath(\"//button[@class=' css-47sehv']\")[0].click()\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9df12b83-44cd-401a-9924-ea3a3a2d117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_elements_by_xpath(\"//a[@class='cc_btn cc_btn_accept_all']\")[0].click()\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "30307039-13b1-4cfa-a6c3-f52c8930d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from contributors tab\n",
    "browser.find_elements_by_xpath(\"//li[@ref='contributors']\")[0].click()\n",
    "time.sleep(0.2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "283e78ea-3f7d-4ef6-b633-b39fb8fa98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_file = browser.page_source\n",
    "soup = BeautifulSoup(soup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d83a6a6a-c1e7-4e7a-9512-f7814e804432",
   "metadata": {},
   "outputs": [],
   "source": [
    "creators = soup.find('div', id='contributors').find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "52fc818f-83dd-4d56-aa7b-4f9fb34b607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "jobs = []\n",
    "for li in creators:\n",
    "    contrib = li.text.strip()\n",
    "    names.append(contrib.split('\\n', 1)[0])\n",
    "    j = contrib.split('\\n', 1)[1]\n",
    "    jobs.append(re.sub('\\s*', '', j))\n",
    "\n",
    "contributors = [names, jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3e9a9bd3-7673-4270-8d15-4c0be53569f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Robert Kirkman', 'Tony Moore', 'Cliff Rathburn'],\n",
       " ['Scripts-Letters', 'Pencils-CoverArt-Inks', 'Colors']]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1bd3c6c3-dae7-41f0-8868-a6d4b7a60d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from characters tab\n",
    "browser.find_elements_by_xpath(\"//li[@ref='characters']\")[0].click()\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "883b1d1c-d473-4486-98af-64fd4b998e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_file = browser.page_source\n",
    "soup = BeautifulSoup(soup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ebc7f3a4-ad47-4f25-b8cd-2406c1f52590",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = soup.find('div', id='characters').find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5908440b-31b4-46bc-a30e-f9866b2fbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(characters) == 1 and characters[0].text == 'There have been no characters assigned to this issue':\n",
    "    characters_data == 'no characters assigned'\n",
    "else:\n",
    "    character_data = []\n",
    "    for li in characters:\n",
    "        name = li.find('a').text.strip()\n",
    "        photo_link = li.find('img').get('src')\n",
    "        extra_info = li.find('span').text.strip()\n",
    "        if '(' not in extra_info:\n",
    "            extra_info = ''\n",
    "\n",
    "        event = li.find('span', class_='d').text.strip()\n",
    "        character_data.append([name, photo_link, extra_info, event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "13af3f6e-94cb-4b43-897f-c64d8dd6c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Duane Jones',\n",
       "  '/character-photos/character_27481_t.jpg',\n",
       "  '',\n",
       "  'First appearance of...'],\n",
       " ['Morgan Jones',\n",
       "  '/character-photos/character_27480_t.jpg',\n",
       "  '',\n",
       "  'First appearance of...'],\n",
       " ['Rick Grimes',\n",
       "  '/character-photos/character_25360_t.jpg',\n",
       "  '(Rick Grimes)',\n",
       "  'First appearance of...'],\n",
       " ['Shane Walsh',\n",
       "  '/character-photos/character_27484_t.jpg',\n",
       "  '(Shane Walsh)',\n",
       "  'First appearance of...'],\n",
       " ['Zombies', '/character-photos/character_12938_t.jpg', '', '']]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653318f9-0716-4e26-bf12-e9edcdfd53a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
