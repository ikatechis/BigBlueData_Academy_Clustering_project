{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69eceade-182f-4646-8399-76f1f0a8a2b9",
   "metadata": {},
   "source": [
    "### Comic Book list Scraper from Publisher A-Z list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c6cb5-18e4-4e3f-96da-dc3a97d0f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825086a-0088-465e-85db-3a142a45109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebe33e-1015-45eb-aa27-013750a11df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comic_list_scraper(pub_id, pub_name, letter, link, fake_agent=True):\n",
    "    if fake_agent:\n",
    "        ua = UserAgent()\n",
    "        headers = {'User-agent': f'{ua.random}'}\n",
    "    else:\n",
    "        headers = {'User-agent': ''}\n",
    "    \n",
    "    response = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    titles_lst = soup.find_all('td', class_='title')\n",
    "    titles_lst = [td.find('a') for td in titles_lst]\n",
    "    \n",
    "    titles_links = [a['href'] for a in titles_lst if a['href'] is not None]\n",
    "    titles = [a.text.strip() for a in titles_lst]\n",
    "    volume = [td.text.strip() for td in soup.find_all('td', class_='volume')]\n",
    "    years = [td.text.strip() for td in soup.find_all('td', class_='years')]\n",
    "    issues = [td.text.strip() for td in soup.find_all('td', class_='issues data-column')]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "                        'pub_id': [pub_id]*len(titles),\n",
    "                        'pub_name': [pub_name]*len(titles),\n",
    "                        'letter': [letter]*len(titles),\n",
    "                        'title': titles,\n",
    "                        'title_link': titles_links,\n",
    "                        'volume': volume,\n",
    "                        'years': years,\n",
    "                        'issues': issues,\n",
    "        \n",
    "                        })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde1236-201b-4b5c-809a-b3fe4be90e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comic_list_scraper(3, 'image-comics', 'w', main_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb72ef9-57d3-4194-8ae4-f811514a6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs = pd.read_csv('publishers_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fc12d-95f8-4b37-be7c-9c9bf763d525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_link = 'https://comicbookrealm.com'\n",
    "titles_data = []\n",
    "# pubs = pubs.iloc[1090:, :]\n",
    "iterates = tqdm(zip(range(len(pubs.id)), pubs.id, pubs.name, pubs.titles_AZ.apply(eval)))\n",
    "for i, id, name, titles in iterates:\n",
    "    iterates.set_description(f\"Processing: {name} - {i + 1} out of {pubs.shape[0]}\")\n",
    "\n",
    "    for title in titles:\n",
    "        letter = title[-1]\n",
    "        link = site_link + title[0]\n",
    "        try:\n",
    "            dat = comic_list_scraper(id, name, letter, link, fake_agent=False)\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                dat = comic_list_scraper(id, name, letter, link, fake_agent=False)\n",
    "            except:\n",
    "                continue\n",
    "        titles_data.append(dat)\n",
    "        time.sleep(0.2 + random.random())\n",
    "        \n",
    "    if i%1000 == 0 and i > 0:\n",
    "        temp = pd.concat(titles_data, axis=0)\n",
    "        temp.to_csv(f'titles_list_{i}.csv')\n",
    "        \n",
    "df_titles = pd.concat(titles_data).reset_index(drop=True)\n",
    "df_titles.to_csv('titles_list_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ecd54-1816-4526-bf66-049774ca1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.concat(titles_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f0f46-5abb-48af-81ec-d3c1f5921759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ba535-a165-418d-a5d2-22ab5b3b1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.to_csv('titles_list_data-part2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb77b34-0a1e-4f5c-92c9-588064a2dc4b",
   "metadata": {},
   "source": [
    "### Minimal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625da098-2bab-4d90-bf10-dd200a054c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = 'w'\n",
    "pub_id = '3'\n",
    "main_link = 'https://comicbookrealm.com/publisher/3/image-comics/w' # Normally we get this from publishers dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b064c8-ae6f-4935-b43f-e662bb2ec515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdedf73-67cc-404f-bd7f-f3feae221eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': f'{ua.random}'}\n",
    "response = requests.get(main_link, headers=headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67d303-ed72-43b5-bc05-417d2141ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc6849-4561-46bc-af77-f9b4f7a66fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = soup.find_all('td', class_='title')\n",
    "titles_lst = [td.find('a') for td in titles_lst]\n",
    "\n",
    "titles_links = [a['href'] for a in titles_lst if a['href'] is not None]\n",
    "\n",
    "titles = [a.text for a in titles_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370d28f-3b9e-4850-89cf-9934d8f0c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = [td.text.strip() for td in soup.find_all('td', class_='volume')]\n",
    "years = [td.text.strip() for td in soup.find_all('td', class_='years')]\n",
    "issues = [td.text.strip() for td in soup.find_all('td', class_='issues data-column')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd9439-4fa5-41d2-9462-ce8da6e6538e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
