{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771399f-b679-4952-ac90-5bce52101129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autotime\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import  silhouette_score\n",
    "from sklearn import datasets\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b462a7-ddf5-4f77-aec5-d0de11937b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_colwidth = 50\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7d2ce-2df9-45ef-a857-a82e9e88d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_featurized.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b68c6-6515-4844-b0f2-a16331959518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438433eb-6f5a-41aa-9aab-2f406d4bb935",
   "metadata": {},
   "source": [
    "Due to the vast difference in current values we will only consider issues that are up to 1000 times their initial price. Although unfortunate, it is extremely unlikely that we will see issues that cost hundreds of thousands or millions of dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63e927-b461-4d7a-b3ad-36aef1a47819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.value_over_price < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc10803-3c43-4f19-9f46-aed0225b8ed9",
   "metadata": {},
   "source": [
    "Some features that are very skewed can be combined to one so that we get a more balanced distribution.\n",
    "Since `special`, `event` and some categories from `volume_type` tend to go to the same clusters we can combine them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78388d-a86f-43e6-bc80-6cb8a61d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the special editions to boolean indexing indicating if it is a special edition or not i.e if the \n",
    "# edition is one of \"limited\", \"incentive\" or \"deluxe\" it will be 1 else 0\n",
    "df1.loc[:, 'special'] = df1.special.replace('not', 0)\n",
    "df1.loc[: , 'special'] = df1.special.where(df1.special == 0, 1)\n",
    "df1.loc[: , 'special'] = df1.special.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef1534-08ea-4a9e-93f5-80f6ada30eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the columns for events into 1 column with 1 if there is a special event and 0 if not\n",
    "df1.loc[: , 'event'] = (df1.first_appear_event + df1.death_event + df1.origin_event).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8426c73-7223-4aa7-9aaf-60375767fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['first_appear_event', 'death_event', 'origin_event'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278a375-a5cb-4dba-9d3d-dc10b5820a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine categories 'fanzine', 'fcbd', 'Prepack', 'magazine' and 'four-color' of volume_type\n",
    "# into one category named 'other'\n",
    "df2.loc[:,  'volume_type'] = df2.volume_type.replace(['fanzine', 'magazine', 'Prepack', \n",
    "                                                      'fcbd', 'four-color'], 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ad09c-f2d3-434e-a80e-51bf604295f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf0487-8427-48ee-95e8-57f7997f39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hÎ¿t encoding of volume_type, special\n",
    "df3 = df2.join(pd.get_dummies(df2['volume_type'], prefix='volume_type'))\n",
    "# drop unwanted columns\n",
    "df3 = df3.drop(columns=['volume_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5df5b7-9f10-4937-b919-68d8751d5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9473a4-2eb9-4544-bafb-0413e79e0155",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011827c-9c67-4676-86c4-6e84bbcac8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans(dframe, clusters=4, scaler=None):\n",
    "    if scaler is None:\n",
    "        data = dframe.copy()\n",
    "    else:\n",
    "        data = scaler.fit_transform(dframe.copy())\n",
    "    km = KMeans(n_clusters=clusters)\n",
    "    km.fit(data)\n",
    "    dd = dframe.copy()\n",
    "    dd['kmeans'] = km.labels_\n",
    "    \n",
    "    return dd, km\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751977a8-97bb-4dcf-b373-d6b3d7e8f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = None\n",
    "dff, model = get_kmeans(df3, 3, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e179e7-0c26-4989-ae9b-2584c813a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupby('kmeans')['months_ago'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24cb81-c371-4d9a-8d3b-797d69ec1925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d9a36-6eef-4333-8696-5acb3a41d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = dff.groupby('kmeans').agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91400eeb-e021-451e-a783-32717723f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31ad29-4649-43d9-9f5f-5cee1d6aa412",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.parallel_coordinates(group, 'kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02049af-a6d7-4fce-8e38-3fbd86d3ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['mean', 'median', 'std']\n",
    "to_agg = dict.fromkeys(['value_over_price', 'months_ago', 'issue_nr', 'print_nr', 'searched'], stats)\n",
    "df1.groupby('kmeans').agg(to_agg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9882499-36b3-4595-b26f-9fd5945f3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df1.sample(10000, hue='kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fd679-1854-4906-990d-817c8f5fb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42750989-0ea5-499b-bd87-f0491d35311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(dff.groupby('kmeans').mean().columns)\n",
    "for col in columns:\n",
    "    ax = sns.boxplot(x='kmeans', y=col, data=dff)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07e63b-a21e-4f8a-9d56-9ab1ca31a04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774cc93-c595-4671-bf0f-6647453b74c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc4042-9a24-45e2-8231-364dc023bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9718d-4e9f-4807-a159-f64fa0f383f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = KElbowVisualizer(KMeans(n_clusters=4, random_state=0), colors='yellowbrick')\n",
    "# visualizer.fit(scaled)\n",
    "# visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbaef9-71d3-46b9-b651-550e9f8b6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = SilhouetteVisualizer(KMeans(n_clusters=5, random_state=0), colors='yellowbrick')\n",
    "# visualizer.fit(scaled)\n",
    "# visualizer.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b74ec6-9a2a-449b-a80e-f6c5dcdf9b34",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e88567-d9b4-49c1-b8f1-fe7ff6e837b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dendrogram\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, memory='./agglo_cache/', n_clusters=None,  \n",
    "                                linkage='ward')\n",
    "\n",
    "# take a sample from data\n",
    "sample = df_dum.sample(1000)\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_sampled = scaler.fit_transform(sample)\n",
    "model = model.fit(scaled_sampled)\n",
    "\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode=\"level\", p=100)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
